#!/bin/bash

# Script to initialize Ollama with qwen2.5:0.5b model for 2GB RAM server
# This script should be run after Ollama container is started

echo "ğŸš€ Initializing Ollama for 2GB RAM server..."

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
max_attempts=30
attempt=0

while [ $attempt -lt $max_attempts ]; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama is ready!"
        break
    fi
    
    echo "â³ Ollama not ready yet, waiting 10 seconds... (attempt $((attempt + 1))/$max_attempts)"
    sleep 10
    attempt=$((attempt + 1))
done

if [ $attempt -eq $max_attempts ]; then
    echo "âŒ Ollama failed to start within 5 minutes"
    exit 1
fi

# Check available models
echo "ğŸ“‹ Checking available models..."
curl -s http://localhost:11434/api/tags | jq -r '.models[]?.name // empty'

# Pull the lightweight model
echo "ğŸ“¥ Pulling qwen2.5:0.5b model (this may take a few minutes)..."
curl -X POST http://localhost:11434/api/pull -d '{
    "name": "qwen2.5:0.5b"
}' --progress-bar

echo ""

# Wait for model to be available
echo "â³ Waiting for model to be available..."
max_attempts=20
attempt=0

while [ $attempt -lt $max_attempts ]; do
    if curl -s http://localhost:11434/api/tags | grep -q "qwen2.5:0.5b"; then
        echo "âœ… Model qwen2.5:0.5b is ready!"
        break
    fi
    
    echo "â³ Model not ready yet, waiting 15 seconds... (attempt $((attempt + 1))/$max_attempts)"
    sleep 15
    attempt=$((attempt + 1))
done

if [ $attempt -eq $max_attempts ]; then
    echo "âŒ Model failed to load within 5 minutes"
    exit 1
fi

# Test the model
echo "ğŸ§ª Testing model with a simple prompt..."
response=$(curl -s -X POST http://localhost:11434/api/generate -d '{
    "model": "qwen2.5:0.5b",
    "prompt": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?",
    "stream": false
}')

if echo "$response" | grep -q "response"; then
    echo "âœ… Model test successful!"
    echo "ğŸ“ Response: $(echo "$response" | jq -r '.response // "No response"')"
else
    echo "âŒ Model test failed"
    echo "Response: $response"
    exit 1
fi

# Check memory usage
echo "ğŸ’¾ Checking memory usage..."
memory_usage=$(docker stats expense_ollama --no-stream --format "table {{.MemUsage}}" | tail -1)
echo "ğŸ“Š Ollama memory usage: $memory_usage"

# List available models
echo "ğŸ“‹ Available models:"
curl -s http://localhost:11434/api/tags | jq -r '.models[] | "  - \(.name) (\(.size | . / 1024 / 1024 / 1024 | floor)GB)"'

echo ""
echo "ğŸ‰ Ollama initialization completed successfully!"
echo "ğŸ”— Ollama API: http://localhost:11434"
echo "ğŸ“Š Analytics Service: http://localhost:8081"
echo "ğŸ’¡ Model: qwen2.5:0.5b (optimized for 2GB RAM)"
